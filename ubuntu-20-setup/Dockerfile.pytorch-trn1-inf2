# Example pytorch neuron container
# To build:
#    docker build . -f Dockerfile.pt -t neuron-container:pytorch
# To run on EC2 Inf1 instances with AWS DLAMI:
#    docker run -it --net=host --device=/dev/neuron0 neuron-container:pytorch

FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training-neuron:1.11.0-neuron-py38-sdk2.3.0-ubuntu20.04
#FROM 763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-inference-neuronx:1.13.1-neuronx-py310-sdk2.14.1-ubuntu20.04
RUN curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj -C /usr/local/bin --strip-components 1
# Set PATH so micromamba is found
ENV PATH="/usr/local/bin:${PATH}"
COPY conda.yaml conda.yaml
COPY requirements.txt requirements.txt
# Use micromamba to install packages from the conda.yml file into the base environment
RUN micromamba install -y -n base -f conda.yaml && \
micromamba clean --all --yes
ENV PATH="/root/micromamba/bin:${PATH}"
RUN mkdir -p /opt/ml
WORKDIR /opt/app/traiunium